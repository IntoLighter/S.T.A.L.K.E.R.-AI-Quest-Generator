# S.T.A.L.K.E.R. AI Quest Generator

# Генерация текста

В приложении предусмотрены два режима генерации текста: локальный и удалённый.
Более высокое качество результатов достигается при использовании больших удалённых моделей.
Выбор типа генерации осуществляется в настройках приложения.

## Локальная генерация текста

### Установка Ollama

Скачать и установить:

https://ollama.com

Проверка установки:

```bash
ollama --version
```

### Загрузка модели

Рекомендуемые модели:

* `llama3.1:8b` — универсальная
* `mistral:7b` — быстрая и атмосферная
* `qwen3:8b` — хорошо держит инструкции
* `gpt-oss:20b` - продвинутая

Пример загрузки:

```bash
ollama pull qwen3:8b
```

### Запуск Ollama

Запустить Ollama через меню пуск.

## Удалённая генерация текста

### Установка LLM API Key Proxy

Скачать и распаковать:

https://github.com/Mirrowel/LLM-API-Key-Proxy/releases/tag/main%2Fbuild-20260123-1-bf7ab7e

### Получение API ключа

Получить API ключ к какому-либо провайдеру и указать его программе.
Здесь рассказано подробнее:

https://github.com/danclave/TALKER/blob/main/docs/Free_Models_Guide.md

# Генерация иконок

Генерация выполняется локально через ComfyUI.

## Установка ComfyUI

Скачать и установить:

https://www.comfy.org/download

## Конфигурирование

В настройках программы в разделе Server-Config измените Port на 8188.

Также необходимо скачать модель.
1. Откройте настройки ComfyUI.
1. В разделе Server-Config включите параметр Use legacy Manager UI.
1. В верхней центральной части рабочей области нажмите кнопку Custom Nodes Manager.
1. Перейдите в Model Manager.
1. Найдите и установите модель sd_xl_base_1.0.safetensors.

# Заключение

После проделанных настроек можно смело запускать генератор!