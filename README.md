# S.T.A.L.K.E.R. AI Quest Generator

# Генерация текста

В приложении предусмотрены два режима генерации текста: локальный и удалённый.
Более высокое качество результатов достигается при использовании больших удалённых моделей.
Выбор типа генерации осуществляется в настройках приложения.

## Локальная генерация текста

### Установка Ollama

Скачать и установить:

https://ollama.com

Проверка установки:

```bash
ollama --version
```

### Загрузка модели

Рекомендуемые модели:

* `llama3.1:8b` — универсальная
* `mistral:7b` — быстрая и атмосферная
* `qwen3:8b` — хорошо держит инструкции
* `gpt-oss:20b` - продвинутая

Пример загрузки:

```bash
ollama pull llama3.1:8b
```

### Запуск Ollama

После установки Ollama автоматически поднимает локальный API:

```
http://localhost:11434
```

Проверка доступности:

```bash
curl http://localhost:11434/api/tags
```

## Удалённая генерация текста

### Установка LLM API Key Proxy

Скачать и распаковать:

https://github.com/Mirrowel/LLM-API-Key-Proxy/releases/tag/main%2Fbuild-20260123-1-bf7ab7e

### Получение API ключа

Получить API ключ к какому-либо провайдеру и указать его программе.
Здесь рассказано подробнее:

https://github.com/danclave/TALKER/blob/main/docs/Free_Models_Guide.md

# Генерация иконок

Генерация выполняется локально через ComfyUI.

## Установка ComfyUI

Скачать и установить:

https://www.comfy.org/download

## Конфигурирование

После успешного запуска программы необходимо в настройках в разделе Server-Config
изменить Port на 8188.

# Заключение

После проделанных настроек можно смело запускать генерацию!